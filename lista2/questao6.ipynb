{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haJ2HABFXJUh"
      },
      "source": [
        "## Questão 6\n",
        "\n",
        "Pesquise sobre redes neurais recorrentes LSTM. Apresente neste estudo aplicações das\n",
        "LSTM deep learning. Seguem abaixo sugestões de aplicações.\n",
        "\n",
        "- i) Predição de series temporais (exemplo: predição de palavras no texto, ou predição\n",
        "de ações na bolsa de valores, etc.)\n",
        "- ii) Reconhecimento de voz\n",
        "- iii) Processamento de Linguagem Natural\n",
        "- iv) Outra aplicações de livre escolha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icWbxpDp4vwj"
      },
      "source": [
        "This study was done by Tiago Dias and its original model can be accessed here [[Link]](https://dadosaocubo.com/processamento-de-linguagem-natural-com-tensorflow/)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVqhqCV8XKnq",
        "outputId": "ab1aba53-e4cb-4a9b-d672-e1f64895e0fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wordninja\n",
            "  Downloading wordninja-2.0.0.tar.gz (541 kB)\n",
            "\u001b[K     |████████████████████████████████| 541 kB 19.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: wordninja\n",
            "  Building wheel for wordninja (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wordninja: filename=wordninja-2.0.0-py3-none-any.whl size=541551 sha256=a1b552c2709978fd312f9884ee539798d4a0254db44772f3be61f90dfd9887b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/3f/eb/a2692e3d2b9deb1487b09ba4967dd6920bd5032bfd9ff7acfc\n",
            "Successfully built wordninja\n",
            "Installing collected packages: wordninja\n",
            "Successfully installed wordninja-2.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install wordninja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0VurOTRXXnT",
        "outputId": "7e4e238f-7b92-4e15-843d-da8474d3d99d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "# Importação das bibliotecas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "import wordninja\n",
        "import textblob\n",
        "import collections\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMCkeKTOXayl"
      },
      "outputs": [],
      "source": [
        "# Importação dos dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/dadosaocubo/nlp/master/mental_health.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vji9-8_2Xe61"
      },
      "outputs": [],
      "source": [
        "# Palavras para retirar da análise\n",
        "stop_words = stopwords.words('english')\n",
        "# Variável tamanho da base de teste\n",
        "test_size = 0.1\n",
        "# Variáveis do modelo\n",
        "epochs = 10\n",
        "batch_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4aY1XxAXfjs"
      },
      "outputs": [],
      "source": [
        "# Separando palavras juntas\n",
        "df['text_split'] = df['text'].apply(wordninja.split)\n",
        "df['text_new'] = df['text_split'].apply(TreebankWordDetokenizer().detokenize)\n",
        "# Corrigindo palavras incorretas\n",
        "df['text_new'] = df['text_new'].apply(textblob.TextBlob).apply(textblob.TextBlob.correct).apply(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNHge8xhXhPL"
      },
      "outputs": [],
      "source": [
        "# Excluindo da descrição os números.\n",
        "df['text_new'] = df['text_new'].str.replace('[0-9]+', '', regex=True).copy()\n",
        "# Excluindo da descrição pontuação.\n",
        "df['text_new'] = df['text_new'].str.replace('[,.:;!?]+', ' ', regex=True).copy()\n",
        "# Excluindo da descrição caracteres especiais.\n",
        "df['text_new'] = df['text_new'].str.replace('[/<>()|\\+\\-\\$%&#@\\'\\\"]+', ' ', regex=True).copy()\n",
        "# Colocando todos os caracteres em caixa baixa.\n",
        "df['text_new'] = df['text_new'].str.lower().copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lffsPGDXi1Y"
      },
      "outputs": [],
      "source": [
        "# Função para retirar stop words\n",
        "def tokenize_df(tokenized_words):\n",
        "  tokenized_words = word_tokenize(tokenized_words)\n",
        "  stop = [word for word in tokenized_words if word not in stop_words]\n",
        "  text = TreebankWordDetokenizer().detokenize(stop)\n",
        "  return text\n",
        "# Eliminando as stop words\n",
        "df['text_new'] = df['text_new'].apply(tokenize_df).copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S22yRNfkXk1E"
      },
      "outputs": [],
      "source": [
        "# Selecionando as únicas palavras da variável text_new\n",
        "df['text_new_split'] = df['text_new'].apply(word_tokenize).copy()\n",
        "text = list(df.text_new_split)\n",
        "list_words = [item for sublist in text for item in sublist]\n",
        "list_words = sorted(list_words)\n",
        "only_words = set(list_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUXK_LUHXpCi"
      },
      "outputs": [],
      "source": [
        "# Gerando encoder com o vocabulário das palavras\n",
        "encoder = tfds.deprecated.text.SubwordTextEncoder(vocab_list=only_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4BAcmN5XppZ"
      },
      "outputs": [],
      "source": [
        "# Encode do label\n",
        "label_encode = LabelEncoder()\n",
        "target = label_encode.fit_transform(df['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJzRvJNHXrE5"
      },
      "outputs": [],
      "source": [
        "# Definindo feature e target\n",
        "x = df['text_new']\n",
        "y = target\n",
        "# Dividindo dataset em treino e teste\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-P1QACAXsYu"
      },
      "outputs": [],
      "source": [
        "# Função para criação da matriz\n",
        "def pad_to_size(vec, size):\n",
        "  zeros = [0] * (size - len(vec))\n",
        "  vec.extend(zeros)\n",
        "  return vec\n",
        "# Função para encode do input\n",
        "def encode_input(text_new):\n",
        "  list_x = []\n",
        "  for text in text_new:\n",
        "    text_encode = encoder.encode(text)\n",
        "    text_encode = pad_to_size(text_encode, 64)\n",
        "    list_x.append(text_encode)\n",
        "  # Convertendo x em tensor\n",
        "  input_encode = tf.cast(list_x, tf.float32)\n",
        "  return input_encode\n",
        "# Encode do x_train e x_test\n",
        "x_train = encode_input(x_train)\n",
        "x_test = encode_input(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueJtvgy9Xt5p",
        "outputId": "9774ac8d-a7f5-427a-acc1-c0893deaa91d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 128)         123904    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, None, 128)        98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 128)              98816     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 322,052\n",
            "Trainable params: 322,052\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Criação do modelo de RNN\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "x = layers.Embedding(encoder.vocab_size, 128)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa6FPTCPXvu0",
        "outputId": "57189b07-3be4-472e-91f2-dbc6c9efdd78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "5/5 [==============================] - 14s 962ms/step - loss: 1.3084 - accuracy: 0.4910 - val_loss: 1.0847 - val_accuracy: 0.5968\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 2s 470ms/step - loss: 1.1335 - accuracy: 0.5668 - val_loss: 1.0661 - val_accuracy: 0.5968\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 2s 455ms/step - loss: 1.1150 - accuracy: 0.5686 - val_loss: 1.0410 - val_accuracy: 0.5968\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 2s 472ms/step - loss: 1.0773 - accuracy: 0.5686 - val_loss: 0.9564 - val_accuracy: 0.5968\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 2s 467ms/step - loss: 0.9524 - accuracy: 0.6227 - val_loss: 0.7686 - val_accuracy: 0.7742\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 2s 442ms/step - loss: 0.8708 - accuracy: 0.7184 - val_loss: 0.6711 - val_accuracy: 0.8226\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 2s 470ms/step - loss: 0.6509 - accuracy: 0.7708 - val_loss: 0.6025 - val_accuracy: 0.8065\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 2s 454ms/step - loss: 0.6131 - accuracy: 0.7708 - val_loss: 0.5953 - val_accuracy: 0.7903\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 2s 444ms/step - loss: 0.5405 - accuracy: 0.7816 - val_loss: 0.6087 - val_accuracy: 0.7419\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 2s 447ms/step - loss: 0.5250 - accuracy: 0.7798 - val_loss: 0.6373 - val_accuracy: 0.7419\n"
          ]
        }
      ],
      "source": [
        "# Compilando modelo e configurando o processo de treinamento\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=['accuracy'])\n",
        "# Treinando o modelo\n",
        "history = model.fit(x_train, y_train, epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6pF-5rAXyO5",
        "outputId": "88cb3e41-44c5-4e1e-c714-1ec78ca1d058"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 40ms/step - loss: 0.6373 - accuracy: 0.7419\n",
            "Test Loss: 0.6373046040534973\n",
            "Test Accuracy: 0.7419354915618896\n"
          ]
        }
      ],
      "source": [
        "# Testando a qualidade do modelo\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test Loss: {}'.format(test_loss))\n",
        "print('Test Accuracy: {}'.format(test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4gXhIXvX1G_"
      },
      "outputs": [],
      "source": [
        "# Função para predição\n",
        "def sample_predict(sample_pred_text):\n",
        "  encoded_sample_pred_text = encoder.encode(sample_pred_text)\n",
        "  encoded_sample_pred_text = tf.cast(encoded_sample_pred_text, tf.float32)\n",
        "  predictions = model.predict(tf.expand_dims(encoded_sample_pred_text, 0))\n",
        "  return (predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6-qLFfVX16I",
        "outputId": "2a09bd2e-dc0e-4ebf-90a6-d628e71a211b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "O exemplo \"feel better die happy\" foi classificado como \"Depression\"\n"
          ]
        }
      ],
      "source": [
        "# Predição do exemplo\n",
        "example = 'feel better die happy'\n",
        "predictions = sample_predict(example)\n",
        "probabilities = [np.argmax(predictions[0])]\n",
        "# Retornando os labels\n",
        "new_label = label_encode.inverse_transform(probabilities)\n",
        "print('O exemplo \"{}\" foi classificado como \"{}\"'.format(example, new_label[0])) "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.1 ('venv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "f995094313285ca45e02641952721eb82d851a2ebba119a240e7e1eae8de5dae"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
